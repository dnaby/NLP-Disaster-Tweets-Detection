{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: center; color: #BD6C37;\"> <i> Ecole Polytechnique de Thi√®s <br>  D√©partement G√©nie Informatique et T√©l√©communications </i> </h4>\n",
    "<h1 style=\"text-align: center\"> Principes MLOps </h1>\n",
    "<h5 style=\"text-align: center\">DIC3-GIT, 2023-2024</h5>\n",
    "<h5 style=\"text-align: center\">Mme Mously DIAW</h5>\n",
    "<h1 style=\"text-align: center; color:#90edaa\">Projet mati√®re : Natural Language Processing with Disaster Tweets</h1>\n",
    "<h5 style=\"text-align: center\"> Par Kikia DIA, Mouhamadou Naby DIA, Ndeye Awa SALANE </h5>\n",
    "<h3 style=\"text-align: center; color:#9000aa; text-decoration:underline\"> II. Models Exploration </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    "### Sommaire\n",
    "#### [Introduction](#1)\n",
    "1. [Features Selection](#3)\n",
    "1. [Vectorisation](#2)\n",
    "1. [Models building](#4)\n",
    "1. [Pipeline](#8)\n",
    "#### [Conclusion](#5)\n",
    "* <i>[References](#6)</i>\n",
    "* <i>[Authors](#7)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> \n",
    "#### Introduction [‚èÆÔ∏è]()[üëÜüèΩ](#0)[‚è≠Ô∏è](#2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter le r√©pertoire parent pour les imports de module\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import pycaret\n",
    "from pycaret.classification import *\n",
    "from pyngrok import ngrok\n",
    "import ppscore as pps\n",
    "import seaborn as sns\n",
    "from settings.params import MODEL_PARAMS, SEED\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from src.data.make_dataset import get_dataset\n",
    "from xgboost import XGBClassifier\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = get_dataset(raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our Deeds Reason earthquake may ALLAH Forgive we</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near La Ronge Sask Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all resident ask shelter place notify officer ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfire evacuation order Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just get send photo Ruby Alaska smoke wildfire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN   our Deeds Reason earthquake may ALLAH Forgive we   \n",
       "1   4     NaN      NaN              forest fire near La Ronge Sask Canada   \n",
       "2   5     NaN      NaN  all resident ask shelter place notify officer ...   \n",
       "3   6     NaN      NaN  people receive wildfire evacuation order Calif...   \n",
       "4   7     NaN      NaN  just get send photo Ruby Alaska smoke wildfire...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> \n",
    "#### 1. Feature Selection [‚èÆÔ∏è](#1)[üëÜüèΩ](#0)[‚è≠Ô∏è](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       our Deeds Reason earthquake may ALLAH Forgive ...\n",
       "1           forest fire near La Ronge Sask Canada nan nan\n",
       "2       all resident ask shelter place notify officer ...\n",
       "3       people receive wildfire evacuation order Calif...\n",
       "4       just get send photo Ruby Alaska smoke wildfire...\n",
       "                              ...                        \n",
       "7608    two giant crane hold bridge collapse nearby ho...\n",
       "7609    ariaahrary TheTawniest the control wild fire C...\n",
       "7610                     M UTCkm S Volcano Hawaii nan nan\n",
       "7611    Police investigate ebike collide car Little Po...\n",
       "7612    the late More home raze Northern California Wi...\n",
       "Name: combined_text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate 'text' and 'Keywords' if 'Keywords' is not NaN\n",
    "train['combined_text'] = train.apply(\n",
    "    # lambda row: f\"{row['text']} {row['keyword'] or ''} \".strip(),\n",
    "    lambda row: f\"{row['text']} {row['keyword'] or ''} {row['location'] or ''}\".strip(),\n",
    "\n",
    "    axis=1\n",
    ")\n",
    "X = train['combined_text']\n",
    "y = train['target']\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CHI2 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Sample data - Replace this with your tweets and labels\n",
    "# data = train\n",
    "# tweets = data[\"text\"]\n",
    "# labels = data[\"target\"]\n",
    "\n",
    "# # Convert text data to numerical features\n",
    "# vectorizer = CountVectorizer(stop_words='english')\n",
    "# X = vectorizer.fit_transform(tweets)\n",
    "\n",
    "\n",
    "# # Apply Chi-Square test\n",
    "# chi2_scores, p_values = chi2(X, y)\n",
    "\n",
    "# # Create a DataFrame to view feature names and their scores\n",
    "# feature_names = vectorizer.get_feature_names_out()\n",
    "# chi2_df = pd.DataFrame({'Feature': feature_names, 'Chi2 Score': chi2_scores})\n",
    "\n",
    "# # Sort by Chi2 Score in descending order\n",
    "# chi2_df = chi2_df.sort_values(by='Chi2 Score', ascending=False)\n",
    "\n",
    "# # Display the top features\n",
    "# print(chi2_df.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> \n",
    "#### 2. Vectorisation [‚èÆÔ∏è](#2)[üëÜüèΩ](#0)[‚è≠Ô∏è](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vect = cv.fit_transform(X)\n",
    "X_vect = X_vect.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_vect = tfidf.fit_transform(X)\n",
    "# X_vect = X_vect\n",
    "# X_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(X_vect[2].T.todense(),\n",
    "#     \tindex=tfidf.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "# df = df.sort_values('TF-IDF', ascending=False)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess the text data\n",
    "# def preprocess_text(text):\n",
    "#     # Tokenize the text\n",
    "#     tokens = word_tokenize(text.lower())\n",
    "#     return tokens\n",
    "\n",
    "# # Apply preprocessing to the text data\n",
    "# X_tokenized = X.apply(preprocess_text)\n",
    "\n",
    "# # Train Word2Vec model\n",
    "# word2vec_model = Word2Vec(sentences=X_tokenized, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# # Transform text data into vectors by averaging the word vectors\n",
    "# def transform_text_to_vector(tokens, model):\n",
    "#     word_vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "#     if len(word_vectors) == 0:\n",
    "#         return np.zeros(model.vector_size)\n",
    "#     return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# X_vect = X_tokenized.apply(lambda tokens: transform_text_to_vector(tokens, word2vec_model))\n",
    "# X_vect = np.vstack(X_vect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"3\"></a> \n",
    "#### 3. Model building [‚èÆÔ∏è](#3)[üëÜüèΩ](#0)[‚è≠Ô∏è](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train / Validation split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect, X_val_vect, y_train, y_val = train_test_split(X_vect, y, test_size=0.2, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set up MLflow tracking\n",
    "local_registry = \"sqlite:///mlruns.db\"\n",
    "mlflow.set_tracking_uri(local_registry)\n",
    "\n",
    "# Create an experiment\n",
    "exp_name = \"disaster_tweets_classification\"\n",
    "experiment = mlflow.get_experiment_by_name(exp_name)\n",
    "if not experiment:\n",
    "    experiment_id = mlflow.create_experiment(exp_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_22349_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_22349\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_22349_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_22349_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_22349_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_22349_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_22349_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_22349_row1_col1\" class=\"data row1 col1\" >target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_22349_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_22349_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_22349_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_22349_row3_col1\" class=\"data row3 col1\" >(7613, 17348)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_22349_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_22349_row4_col1\" class=\"data row4 col1\" >(7613, 17348)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_22349_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_22349_row5_col1\" class=\"data row5 col1\" >(5329, 17348)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_22349_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_22349_row6_col1\" class=\"data row6 col1\" >(2284, 17348)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_22349_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_22349_row7_col1\" class=\"data row7 col1\" >17347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_22349_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_22349_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_22349_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_22349_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_22349_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_22349_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_22349_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_22349_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_22349_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_22349_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_22349_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_22349_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_22349_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_22349_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_22349_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_22349_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_22349_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_22349_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_22349_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_22349_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_22349_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_22349_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_22349_row18_col1\" class=\"data row18 col1\" >e6b6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e910a676d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Initiated</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>07:56:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Status</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Fitting 10 Folds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <td>. . . . . . . . . . . . . . . . . .</td>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        \n",
       "                                                                        \n",
       "Initiated  . . . . . . . . . . . . . . . . . .                  07:56:24\n",
       "Status     . . . . . . . . . . . . . . . . . .          Fitting 10 Folds\n",
       "Estimator  . . . . . . . . . . . . . . . . . .  Decision Tree Classifier"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6e862 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_6e862_row0_col0, #T_6e862_row0_col1, #T_6e862_row0_col2, #T_6e862_row0_col3, #T_6e862_row0_col4, #T_6e862_row0_col5, #T_6e862_row0_col6, #T_6e862_row0_col7, #T_6e862_row0_col8, #T_6e862_row1_col0, #T_6e862_row1_col1, #T_6e862_row1_col2, #T_6e862_row1_col3, #T_6e862_row1_col4, #T_6e862_row1_col5, #T_6e862_row1_col6, #T_6e862_row1_col7, #T_6e862_row1_col8, #T_6e862_row2_col0, #T_6e862_row2_col1, #T_6e862_row2_col2, #T_6e862_row2_col3, #T_6e862_row2_col4, #T_6e862_row2_col5, #T_6e862_row2_col6, #T_6e862_row2_col7, #T_6e862_row2_col8 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6e862\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6e862_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_6e862_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_6e862_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_6e862_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_6e862_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_6e862_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_6e862_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_6e862_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_6e862_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6e862_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_6e862_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_6e862_row0_col1\" class=\"data row0 col1\" >0.7851</td>\n",
       "      <td id=\"T_6e862_row0_col2\" class=\"data row0 col2\" >0.8476</td>\n",
       "      <td id=\"T_6e862_row0_col3\" class=\"data row0 col3\" >0.6983</td>\n",
       "      <td id=\"T_6e862_row0_col4\" class=\"data row0 col4\" >0.7787</td>\n",
       "      <td id=\"T_6e862_row0_col5\" class=\"data row0 col5\" >0.7360</td>\n",
       "      <td id=\"T_6e862_row0_col6\" class=\"data row0 col6\" >0.5559</td>\n",
       "      <td id=\"T_6e862_row0_col7\" class=\"data row0 col7\" >0.5584</td>\n",
       "      <td id=\"T_6e862_row0_col8\" class=\"data row0 col8\" >6.4780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e862_level0_row1\" class=\"row_heading level0 row1\" >knn</th>\n",
       "      <td id=\"T_6e862_row1_col0\" class=\"data row1 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_6e862_row1_col1\" class=\"data row1 col1\" >0.7204</td>\n",
       "      <td id=\"T_6e862_row1_col2\" class=\"data row1 col2\" >0.7511</td>\n",
       "      <td id=\"T_6e862_row1_col3\" class=\"data row1 col3\" >0.5004</td>\n",
       "      <td id=\"T_6e862_row1_col4\" class=\"data row1 col4\" >0.7692</td>\n",
       "      <td id=\"T_6e862_row1_col5\" class=\"data row1 col5\" >0.6053</td>\n",
       "      <td id=\"T_6e862_row1_col6\" class=\"data row1 col6\" >0.4038</td>\n",
       "      <td id=\"T_6e862_row1_col7\" class=\"data row1 col7\" >0.4268</td>\n",
       "      <td id=\"T_6e862_row1_col8\" class=\"data row1 col8\" >6.8180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6e862_level0_row2\" class=\"row_heading level0 row2\" >nb</th>\n",
       "      <td id=\"T_6e862_row2_col0\" class=\"data row2 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_6e862_row2_col1\" class=\"data row2 col1\" >0.6193</td>\n",
       "      <td id=\"T_6e862_row2_col2\" class=\"data row2 col2\" >0.6381</td>\n",
       "      <td id=\"T_6e862_row2_col3\" class=\"data row2 col3\" >0.7721</td>\n",
       "      <td id=\"T_6e862_row2_col4\" class=\"data row2 col4\" >0.5397</td>\n",
       "      <td id=\"T_6e862_row2_col5\" class=\"data row2 col5\" >0.6350</td>\n",
       "      <td id=\"T_6e862_row2_col6\" class=\"data row2 col6\" >0.2621</td>\n",
       "      <td id=\"T_6e862_row2_col7\" class=\"data row2 col7\" >0.2818</td>\n",
       "      <td id=\"T_6e862_row2_col8\" class=\"data row2 col8\" >6.5530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1e916a674d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718757ac819f4c0497846a35b965c853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/65 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m clf \u001b[38;5;241m=\u001b[39m setup(data\u001b[38;5;241m=\u001b[39mdf, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m, session_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Compare different models\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mcompare_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Pull the results\u001b[39;00m\n\u001b[0;32m     12\u001b[0m results \u001b[38;5;241m=\u001b[39m pull()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pycaret\\utils\\generic.py:964\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    962\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m globals_d[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[1;32m--> 964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pycaret\\classification\\functional.py:814\u001b[0m, in \u001b[0;36mcompare_models\u001b[1;34m(include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, experiment_custom_tags, probability_threshold, engine, verbose, parallel)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;129m@check_if_global_is_not_none\u001b[39m(\u001b[38;5;28mglobals\u001b[39m(), _CURRENT_EXPERIMENT_DECORATOR_DICT)\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_models\u001b[39m(\n\u001b[0;32m    674\u001b[0m     include: Optional[List[Union[\u001b[38;5;28mstr\u001b[39m, Any]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    690\u001b[0m     parallel: Optional[ParallelBackend] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    691\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Any, List[Any]]:\n\u001b[0;32m    692\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    693\u001b[0m \u001b[38;5;124;03m    This function trains and evaluates performance of all estimators available in the\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;124;03m    model library using cross validation. The output of this function is a score grid\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;124;03m    - No models are logged in ``MLFlow`` when ``cross_validation`` parameter is False.\u001b[39;00m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_CURRENT_EXPERIMENT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    818\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    819\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_select\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_select\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbudget_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbudget_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mturbo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mturbo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobability_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobability_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pycaret\\classification\\oop.py:1180\u001b[0m, in \u001b[0;36mClassificationExperiment.compare_models\u001b[1;34m(self, include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, experiment_custom_tags, probability_threshold, engine, verbose, parallel)\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_engine(estimator\u001b[38;5;241m=\u001b[39mestimator, engine\u001b[38;5;241m=\u001b[39meng, severity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1180\u001b[0m     return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompare_models\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_validation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_select\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_select\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbudget_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbudget_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mturbo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mturbo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_custom_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprobability_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprobability_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparallel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaller_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1201\u001b[0m         \u001b[38;5;66;03m# Reset the models back to the default engines\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:794\u001b[0m, in \u001b[0;36m_SupervisedExperiment.compare_models\u001b[1;34m(self, include, exclude, fold, round, cross_validation, sort, n_select, budget_time, turbo, errors, fit_kwargs, groups, experiment_custom_tags, probability_threshold, verbose, parallel, caller_params)\u001b[0m\n\u001b[0;32m    791\u001b[0m results_columns_to_ignore \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mruntime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcutoff\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    793\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 794\u001b[0m     model, model_fit_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcreate_model_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    795\u001b[0m     model_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpull(pop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[0;32m    797\u001b[0m         np\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m    798\u001b[0m             model_results\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    802\u001b[0m         \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    803\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:1533\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model\u001b[1;34m(self, estimator, fold, round, cross_validation, predict, fit_kwargs, groups, refit, probability_threshold, experiment_custom_tags, verbose, system, add_to_model_list, X_train_data, y_train_data, metrics, display, model_only, return_train_score, error_score, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m model, model_fit_time\n\u001b[0;32m   1531\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m-> 1533\u001b[0m model, model_fit_time, model_results, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_model_with_cv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrefit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1547\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;66;03m# end runtime\u001b[39;00m\n\u001b[0;32m   1550\u001b[0m runtime_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pycaret\\internal\\pycaret_experiment\\supervised_experiment.py:1126\u001b[0m, in \u001b[0;36m_SupervisedExperiment._create_model_with_cv\u001b[1;34m(self, model, data_X, data_y, fit_kwargs, round, cv, groups, metrics, refit, system, display, error_score, return_train_score)\u001b[0m\n\u001b[0;32m   1124\u001b[0m     model_fit_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   1125\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m redirect_output(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger):\n\u001b[1;32m-> 1126\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpipeline_with_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_X\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m            \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m model_fit_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   1140\u001b[0m model_fit_time \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(model_fit_end \u001b[38;5;241m-\u001b[39m model_fit_start)\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Combine features and labels into a DataFrame\n",
    "df = pd.DataFrame(X_vect)\n",
    "df['target'] = y\n",
    "\n",
    "# Use PyCaret for classification\n",
    "clf = setup(data=df, target='target', session_id=123)\n",
    "\n",
    "# Compare different models\n",
    "best_model = compare_models()\n",
    "\n",
    "# Pull the results\n",
    "results = pull()\n",
    "\n",
    "# Print the results\n",
    "print(results)\n",
    "\n",
    "# Finalize the best model (optional)\n",
    "final_model = finalize_model(best_model)\n",
    "\n",
    "# Print the best model details\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search for some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_with_grid_search(model, param_grid, X_train, y_train, X_val, y_val, model_name):\n",
    "    # Perform Grid Search\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "                               cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model from Grid Search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name, experiment_id=experiment_id) as run:\n",
    "        # Train the best model\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "        # Calculate metrics for training set\n",
    "        train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "        train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "        train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "        # Calculate metrics for validation set\n",
    "        val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "        val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "        val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric(\"train_f1_score\", train_f1)\n",
    "        mlflow.log_metric(\"train_precision\", train_precision)\n",
    "        mlflow.log_metric(\"train_recall\", train_recall)\n",
    "        mlflow.log_metric(\"val_f1_score\", val_f1)\n",
    "        mlflow.log_metric(\"val_precision\", val_precision)\n",
    "        mlflow.log_metric(\"val_recall\", val_recall)\n",
    "\n",
    "        # Log the best model\n",
    "        mlflow.sklearn.log_model(best_model, model_name, input_example=X_train[:30])\n",
    "\n",
    "        # Print metrics\n",
    "        print(f'{model_name} Training F1 Score: {train_f1}')\n",
    "        print(f'{model_name} Training Precision: {train_precision}')\n",
    "        print(f'{model_name} Training Recall: {train_recall}')\n",
    "        print(f'{model_name} Validation F1 Score: {val_f1}')\n",
    "        print(f'{model_name} Validation Precision: {val_precision}')\n",
    "        print(f'{model_name} Validation Recall: {val_recall}')\n",
    "\n",
    "        # Print best parameters\n",
    "        print(f'Best parameters for {model_name}: {best_params}')\n",
    "    return grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classification models with fixed random seed\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=SEED),\n",
    "    'SVC': SVC(C=100, gamma='scale', kernel='linear', random_state=SEED),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=SEED),\n",
    "    'Logistic Regression': LogisticRegression()\n",
    "}\n",
    "\n",
    "# Parameter grids for each model\n",
    "param_grids = {\n",
    "    'RandomForestClassifier': [{\n",
    "        'n_estimators': [10, 50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }],\n",
    "    'SVC': [{\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "    }],\n",
    "    # 'Naive Bayes': [{\n",
    "    #     'alpha': [0.01, 0.1, 1, 10]\n",
    "    # }],\n",
    "    'KNN': [{\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "    }],\n",
    "    'XGBoost': [{\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 6, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    }],\n",
    "    'Logistic Regression': [{\n",
    "        'C': [0.01, 0.1, 0.8, 1, 10, 100],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        'max_iter': [100, 200, 500, 1000],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]  # Only used if penalty is 'elasticnet'\n",
    "    }]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Grid Search on each model\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Performing Grid Search for {model_name}...\")\n",
    "    best_models[model_name] = train_and_evaluate_with_grid_search(model, param_grids[model_name], X_train_vect, y_train, X_val_vect, y_val, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train and evaluate models\n",
    "def train_and_evaluate(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    with mlflow.start_run(run_name=model_name, experiment_id=experiment_id) as run:\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        # Calculate metrics for training set\n",
    "        train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "        train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "        train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "        # Calculate metrics for validation set\n",
    "        val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "        val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "        val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metric(\"train_f1_score\", train_f1)\n",
    "        mlflow.log_metric(\"train_precision\", train_precision)\n",
    "        mlflow.log_metric(\"train_recall\", train_recall)\n",
    "        mlflow.log_metric(\"val_f1_score\", val_f1)\n",
    "        mlflow.log_metric(\"val_precision\", val_precision)\n",
    "        mlflow.log_metric(\"val_recall\", val_recall)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f'{model_name} Training F1 Score: {train_f1}')\n",
    "        print(f'{model_name} Training Precision: {train_precision}')\n",
    "        print(f'{model_name} Training Recall: {train_recall}')\n",
    "        print(f'{model_name} Validation F1 Score: {val_f1}')\n",
    "        print(f'{model_name} Validation Precision: {val_precision}')\n",
    "        print(f'{model_name} Validation Recall: {val_recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(model, param_grids[model_name], X_train_vect, y_train, X_val_vect, y_val, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Grid Search for SVC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/05 17:48:19 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Training F1 Score: 0.731469561795964\n",
      "SVC Training Precision: 0.7544839245352881\n",
      "SVC Training Recall: 0.7431855500821019\n",
      "SVC Validation F1 Score: 0.7088681823804714\n",
      "SVC Validation Precision: 0.7339161906696655\n",
      "SVC Validation Recall: 0.7209455022980958\n",
      "Performing Grid Search for KNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/05 17:48:23 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training F1 Score: 0.7972164457367042\n",
      "KNN Training Precision: 0.8026001172450099\n",
      "KNN Training Recall: 0.8004926108374384\n",
      "KNN Validation F1 Score: 0.7168131822816927\n",
      "KNN Validation Precision: 0.7212164369739648\n",
      "KNN Validation Recall: 0.7209455022980958\n",
      "Performing Grid Search for XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/05 17:48:28 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training F1 Score: 0.9944148250771129\n",
      "XGBoost Training Precision: 0.9944266249852991\n",
      "XGBoost Training Recall: 0.9944170771756978\n",
      "XGBoost Validation F1 Score: 0.7419370728552321\n",
      "XGBoost Validation Precision: 0.7445302718276919\n",
      "XGBoost Validation Recall: 0.7445830597504924\n",
      "Performing Grid Search for Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/05 17:48:31 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training F1 Score: 0.7368152860797609\n",
      "Logistic Regression Training Precision: 0.7450867267846537\n",
      "Logistic Regression Training Recall: 0.7431855500821019\n",
      "Logistic Regression Validation F1 Score: 0.7223453643627269\n",
      "Logistic Regression Validation Precision: 0.7327801535171437\n",
      "Logistic Regression Validation Recall: 0.7288246881155613\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    train_and_evaluate(model,  X_train_vect, y_train, X_val_vect, y_val, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Voting & Stacking Classifiers with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VotingClassifier with the best models\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', best_models['RandomForestClassifier']),\n",
    "    ('svc', best_models['SVC']),\n",
    "    ('nb', best_models['Naive Bayes']),\n",
    "    ('knn', best_models['KNN']),\n",
    "    ('xgb', best_models['XGBoost']),\n",
    "], voting='hard')\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=[\n",
    "    ('rf', best_models['RandomForestClassifier']),\n",
    "    ('svc', best_models['SVC']),\n",
    "    ('nb', best_models['Naive Bayes']),\n",
    "    ('knn', best_models['KNN']),\n",
    "    ('xgb', best_models['XGBoost']),\n",
    "], final_estimator=LogisticRegression(),\n",
    "    cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble_VotingClassifier Training F1 Score: 0.8886796365167872\n",
      "Ensemble_VotingClassifier Training Precision: 0.8943220186883235\n",
      "Ensemble_VotingClassifier Training Recall: 0.8901477832512316\n",
      "Ensemble_VotingClassifier Validation F1 Score: 0.7897609423218112\n",
      "Ensemble_VotingClassifier Validation Precision: 0.8027665387593974\n",
      "Ensemble_VotingClassifier Validation Recall: 0.7944845699277742\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_ensemble(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    with mlflow.start_run(run_name=model_name, experiment_id=experiment_id) as run:\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        # Calculate metrics for training set\n",
    "        train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "        train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "        train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "        # Calculate metrics for validation set\n",
    "        val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "        val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "        val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_param(\"ensemble_method\", \"VotingClassifier\")\n",
    "        mlflow.log_metric(\"train_f1_score\", train_f1)\n",
    "        mlflow.log_metric(\"train_precision\", train_precision)\n",
    "        mlflow.log_metric(\"train_recall\", train_recall)\n",
    "        mlflow.log_metric(\"val_f1_score\", val_f1)\n",
    "        mlflow.log_metric(\"val_precision\", val_precision)\n",
    "        mlflow.log_metric(\"val_recall\", val_recall)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, model_name, input_example=X_train[:30])\n",
    "\n",
    "        # Print metrics\n",
    "        print(f'{model_name} Training F1 Score: {train_f1}')\n",
    "        print(f'{model_name} Training Precision: {train_precision}')\n",
    "        print(f'{model_name} Training Recall: {train_recall}')\n",
    "        print(f'{model_name} Validation F1 Score: {val_f1}')\n",
    "        print(f'{model_name} Validation Precision: {val_precision}')\n",
    "        print(f'{model_name} Validation Recall: {val_recall}')\n",
    "\n",
    "# Train and evaluate the ensemble model\n",
    "train_and_evaluate_ensemble(voting_clf, X_train_vect, y_train, X_val_vect, y_val, \"Ensemble_VotingClassifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble_StackingClassifier Training F1 Score: 0.9048439941983731\n",
      "Ensemble_StackingClassifier Training Precision: 0.9071708803501655\n",
      "Ensemble_StackingClassifier Training Recall: 0.9055829228243021\n",
      "Ensemble_StackingClassifier Validation F1 Score: 0.8022127414966628\n",
      "Ensemble_StackingClassifier Validation Precision: 0.8061925456564542\n",
      "Ensemble_StackingClassifier Validation Recall: 0.804333552199606\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_ensemble(stacking_clf, X_train_vect, y_train, X_val_vect, y_val, \"Ensemble_StackingClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking UI: NgrokTunnel: \"https://5c31-41-82-155-235.ngrok-free.app\" -> \"http://localhost:5000\"\n"
     ]
    }
   ],
   "source": [
    "# Terminate open tunnels if they exist\n",
    "ngrok.kill()\n",
    "NGROK_AUTH_TOKEN = \"2iXzpfikPynAXlcC1qn3NDhkhMS_7BbPuGQ5Sc8R7aohgotz6\"\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "public_url = ngrok.connect(5000)\n",
    "print(\"MLflow Tracking UI:\", public_url)\n",
    "\n",
    "# Transition models to production\n",
    "client = MlflowClient()\n",
    "for model_name in models.keys():\n",
    "    try:\n",
    "        model_versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "        if model_versions:\n",
    "            # Get the latest model version\n",
    "            latest_version = model_versions[-1]\n",
    "            client.transition_model_version_stage(\n",
    "                name=model_name,\n",
    "                version=latest_version.version,\n",
    "                stage=\"production\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Error transitioning model {model_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"3\"></a> \n",
    "#### 4. Pipeline [‚èÆÔ∏è](#4)[üëÜüèΩ](#0)[‚è≠Ô∏è](#6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_pip=Pipeline(\n",
    "                [\n",
    "                    ('tf_idf',TfidfVectorizer(ngram_range=(1,1))),\n",
    "                    ('model',LogisticRegression(C=.8,solver='sag',max_iter=1000))\n",
    "                ]\n",
    "                )\n",
    "idf_pip.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> \n",
    "#### Conclusion [‚èÆÔ∏è](#4)[üëÜüèΩ](#0)[‚è≠Ô∏è](#6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"6\"></a> \n",
    "#### <i>References</i> [‚èÆÔ∏è](#5)[üëÜüèΩ](#0)[‚è≠Ô∏è](#7)\n",
    "Here is some text with a reference to the [Python documentation](https://docs.python.org/).\n",
    "\n",
    "...\n",
    "\n",
    "Here are some references for more information on the libraries used:\n",
    "\n",
    "- [Pandas documentation](https://pandas.pydata.org/docs/)\n",
    "- [NumPy documentation](https://numpy.org/doc/stable/)\n",
    "- [Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html)\n",
    "\n",
    "üçÄ Auteurs\n",
    "- üßëüèæ‚Äçüíª Kikia DIA\n",
    "- üßëüèæ‚Äçüíª Mouhamadou Naby DIA\n",
    "- üßëüèæ‚Äçüíª Ndeye Awa SALANE\n",
    "\n",
    "üçÄ Affiliations\n",
    "- üéì Ecole Polytechnique de THIES\n",
    "\n",
    "üçÄ D√©partement \n",
    "- üíª G√©nie Informatique et T√©l√©communications\n",
    "\n",
    "üçÄ Niveau\n",
    "- üìö DIC3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
