{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: center; color: #BD6C37;\"> <i> Ecole Polytechnique de Thi√®s <br>  D√©partement G√©nie Informatique et T√©l√©communications </i> </h4>\n",
    "<h1 style=\"text-align: center\"> Principes MLOps </h1>\n",
    "<h5 style=\"text-align: center\">DIC3-GIT, 2023-2024</h5>\n",
    "<h5 style=\"text-align: center\">Mme Mously DIAW</h5>\n",
    "<h1 style=\"text-align: center; color:#90edaa\">Projet mati√®re : Natural Language Processing with Disaster Tweets</h1>\n",
    "<h5 style=\"text-align: center\"> Par Kikia DIA, Mouhamadou Naby DIA, Ndeye Awa SALANE </h5>\n",
    "<h3 style=\"text-align: center; color:#9000aa; text-decoration:underline\"> II. Models Exploration </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    "### Sommaire\n",
    "#### [Introduction](#1)\n",
    "1. [Features Selection](#3)\n",
    "1. [Vectorisation](#2)\n",
    "1. [Models building](#4)\n",
    "1. [Pipeline](#8)\n",
    "#### [Conclusion](#5)\n",
    "* <i>[References](#6)</i>\n",
    "* <i>[Authors](#7)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> \n",
    "#### Introduction [‚èÆÔ∏è]()[üëÜüèΩ](#0)[‚è≠Ô∏è](#2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter le r√©pertoire parent pour les imports de module\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import pycaret\n",
    "from pycaret.classification import *\n",
    "from pyngrok import ngrok\n",
    "import ppscore as pps\n",
    "import seaborn as sns\n",
    "from settings.params import MODEL_PARAMS, SEED\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from src.data.make_dataset import get_dataset\n",
    "from xgboost import XGBClassifier\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = get_dataset(raw=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7591, 5)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deed reason earthquake may forgive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>resident ask shelter place notify officer evac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>receive wildfire evacuation order</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>get send photo ruby smoke pour school</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN                 deed reason earthquake may forgive   \n",
       "1   4     NaN      NaN                         forest fire near la canada   \n",
       "2   5     NaN      NaN  resident ask shelter place notify officer evac...   \n",
       "3   6     NaN      NaN                  receive wildfire evacuation order   \n",
       "4   7     NaN      NaN              get send photo ruby smoke pour school   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.dropna(subset=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7591, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> \n",
    "#### 1. Feature Selection [‚èÆÔ∏è](#1)[üëÜüèΩ](#0)[‚è≠Ô∏è](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      deed reason earthquake may forgive\n",
       "1                              forest fire near la canada\n",
       "2       resident ask shelter place notify officer evac...\n",
       "3                       receive wildfire evacuation order\n",
       "4                   get send photo ruby smoke pour school\n",
       "                              ...                        \n",
       "7586     two giant crane hold bridge collapse nearby home\n",
       "7587    aria control wild fire even northern part stat...\n",
       "7588                                              volcano\n",
       "7589    police investigate bike collide car little bik...\n",
       "7590                     late home raze northern wildfire\n",
       "Name: text, Length: 7591, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate 'text' and 'Keywords' if 'Keywords' is not NaN\n",
    "# train['combined_text'] = train.apply(\n",
    "#     # lambda row: f\"{row['text']} {row['keyword'] or ''} \".strip(),\n",
    "#     lambda row: f\"{row['text']} {row['keyword'] or ''} {row['location'] or ''}\".strip(),\n",
    "\n",
    "#     axis=1\n",
    "# )\n",
    "# X = train['combined_text']\n",
    "X = train[\"text\"]\n",
    "y = train['target']\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CHI2 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Sample data - Replace this with your tweets and labels\n",
    "# data = train\n",
    "# tweets = data[\"text\"]\n",
    "# labels = data[\"target\"]\n",
    "\n",
    "# # Convert text data to numerical features\n",
    "# vectorizer = CountVectorizer(stop_words='english')\n",
    "# X = vectorizer.fit_transform(tweets)\n",
    "\n",
    "\n",
    "# # Apply Chi-Square test\n",
    "# chi2_scores, p_values = chi2(X, y)\n",
    "\n",
    "# # Create a DataFrame to view feature names and their scores\n",
    "# feature_names = vectorizer.get_feature_names_out()\n",
    "# chi2_df = pd.DataFrame({'Feature': feature_names, 'Chi2 Score': chi2_scores})\n",
    "\n",
    "# # Sort by Chi2 Score in descending order\n",
    "# chi2_df = chi2_df.sort_values(by='Chi2 Score', ascending=False)\n",
    "\n",
    "# # Display the top features\n",
    "# print(chi2_df.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> \n",
    "#### 2. Vectorisation [‚èÆÔ∏è](#2)[üëÜüèΩ](#0)[‚è≠Ô∏è](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_vect = cv.fit_transform(X)\n",
    "# X_vect = X_vect.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vect = tfidf.fit_transform(X)\n",
    "X_vect = X_vect.toarray()\n",
    "X_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(X_vect[2].T.todense(),\n",
    "#     \tindex=tfidf.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "# df = df.sort_values('TF-IDF', ascending=False)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess the text data\n",
    "# def preprocess_text(text):\n",
    "#     # Tokenize the text\n",
    "#     tokens = word_tokenize(text.lower())\n",
    "#     return tokens\n",
    "\n",
    "# # Apply preprocessing to the text data\n",
    "# X_tokenized = X.apply(preprocess_text)\n",
    "\n",
    "# # Train Word2Vec model\n",
    "# word2vec_model = Word2Vec(sentences=X_tokenized, vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# # Transform text data into vectors by averaging the word vectors\n",
    "# def transform_text_to_vector(tokens, model):\n",
    "#     word_vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "#     if len(word_vectors) == 0:\n",
    "#         return np.zeros(model.vector_size)\n",
    "#     return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# X_vect = X_tokenized.apply(lambda tokens: transform_text_to_vector(tokens, word2vec_model))\n",
    "# X_vect = np.vstack(X_vect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"3\"></a> \n",
    "#### 3. Model building [‚èÆÔ∏è](#3)[üëÜüèΩ](#0)[‚è≠Ô∏è](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train / Validation split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect, X_val_vect, y_train, y_val = train_test_split(X_vect, y, test_size=0.15, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set up MLflow tracking\n",
    "local_registry = \"sqlite:///mlruns.db\"\n",
    "mlflow.set_tracking_uri(local_registry)\n",
    "\n",
    "# Create an experiment\n",
    "exp_name = \"disaster_tweets_classification\"\n",
    "experiment = mlflow.get_experiment_by_name(exp_name)\n",
    "if not experiment:\n",
    "    experiment_id = mlflow.create_experiment(exp_name)\n",
    "else:\n",
    "    experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine features and labels into a DataFrame\n",
    "# df = pd.DataFrame(X_vect)\n",
    "# df['target'] = y\n",
    "\n",
    "# # Use PyCaret for classification\n",
    "# clf = setup(data=df, target='target', session_id=123)\n",
    "\n",
    "# # Compare different models\n",
    "# best_model = compare_models()\n",
    "\n",
    "# # Pull the results\n",
    "# results = pull()\n",
    "\n",
    "# # Print the results\n",
    "# print(results)\n",
    "\n",
    "# # Finalize the best model (optional)\n",
    "# final_model = finalize_model(best_model)\n",
    "\n",
    "# # Print the best model details\n",
    "# print(final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grid Search for some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_with_grid_search(model, param_grid, X_train, y_train, X_val, y_val, model_name):\n",
    "    # Perform Grid Search\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, \n",
    "                               cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model from Grid Search\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name, experiment_id=experiment_id) as run:\n",
    "        # Train the best model\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "        # Calculate metrics for training set\n",
    "        train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "        train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "        train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "        # Calculate metrics for validation set\n",
    "        val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "        val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "        val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_params(best_params)\n",
    "        mlflow.log_metric(\"train_f1_score\", train_f1)\n",
    "        mlflow.log_metric(\"train_precision\", train_precision)\n",
    "        mlflow.log_metric(\"train_recall\", train_recall)\n",
    "        mlflow.log_metric(\"val_f1_score\", val_f1)\n",
    "        mlflow.log_metric(\"val_precision\", val_precision)\n",
    "        mlflow.log_metric(\"val_recall\", val_recall)\n",
    "\n",
    "        # Log the best model\n",
    "        mlflow.sklearn.log_model(best_model, model_name, input_example=X_train[:30])\n",
    "\n",
    "        # Print metrics\n",
    "        print(f'{model_name} Training F1 Score: {train_f1}')\n",
    "        print(f'{model_name} Training Precision: {train_precision}')\n",
    "        print(f'{model_name} Training Recall: {train_recall}')\n",
    "        print(f'{model_name} Validation F1 Score: {val_f1}')\n",
    "        print(f'{model_name} Validation Precision: {val_precision}')\n",
    "        print(f'{model_name} Validation Recall: {val_recall}')\n",
    "\n",
    "        # Print best parameters\n",
    "        print(f'Best parameters for {model_name}: {best_params}')\n",
    "    return grid_search.best_estimator_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classification models with fixed random seed\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state=SEED),\n",
    "    'SVC': SVC(C=100, gamma='scale', kernel='linear', random_state=SEED),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=SEED),\n",
    "    # 'Logistic Regression': LogisticRegression()\n",
    "}\n",
    "\n",
    "# Parameter grids for each model\n",
    "param_grids = {\n",
    "    'RandomForestClassifier': [{\n",
    "        'n_estimators': [10, 50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }],\n",
    "    'SVC': [{\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto'],\n",
    "        'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "    }],\n",
    "    'Naive Bayes': [{\n",
    "        'alpha': [0.01, 0.1, 1, 10]\n",
    "    }],\n",
    "    'KNN': [{\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "    }],\n",
    "    'XGBoost': [{\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 6, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.6, 0.8, 1.0]\n",
    "    }],\n",
    "    'Logistic Regression': [{\n",
    "        'C': [0.01, 0.1, 0.8, 1, 10, 100],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        'max_iter': [100, 200, 500, 1000],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]  # Only used if penalty is 'elasticnet'\n",
    "    }]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Grid Search for RandomForestClassifier...\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    }
   ],
   "source": [
    "# Perform Grid Search on each model\n",
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Performing Grid Search for {model_name}...\")\n",
    "    best_models[model_name] = train_and_evaluate_with_grid_search(model, param_grids[model_name], X_train_vect, y_train, X_val_vect, y_val, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to train and evaluate models\n",
    "def train_and_evaluate(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    with mlflow.start_run(run_name=model_name, experiment_id=experiment_id) as run:\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        # Calculate metrics for training set\n",
    "        train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "        train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "        train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "        # Calculate metrics for validation set\n",
    "        val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "        val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "        val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_params(model.get_params())\n",
    "        mlflow.log_metric(\"train_f1_score\", train_f1)\n",
    "        mlflow.log_metric(\"train_precision\", train_precision)\n",
    "        mlflow.log_metric(\"train_recall\", train_recall)\n",
    "        mlflow.log_metric(\"val_f1_score\", val_f1)\n",
    "        mlflow.log_metric(\"val_precision\", val_precision)\n",
    "        mlflow.log_metric(\"val_recall\", val_recall)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f'{model_name} Training F1 Score: {train_f1}')\n",
    "        print(f'{model_name} Training Precision: {train_precision}')\n",
    "        print(f'{model_name} Training Recall: {train_recall}')\n",
    "        print(f'{model_name} Validation F1 Score: {val_f1}')\n",
    "        print(f'{model_name} Validation Precision: {val_precision}')\n",
    "        print(f'{model_name} Validation Recall: {val_recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate(model, param_grids[model_name], X_train_vect, y_train, X_val_vect, y_val, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/06 20:23:18 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Training F1 Score: 0.9816806422576758\n",
      "RandomForestClassifier Training Precision: 0.9818872281650376\n",
      "RandomForestClassifier Training Recall: 0.98171109733416\n",
      "RandomForestClassifier Validation F1 Score: 0.7823297680413072\n",
      "RandomForestClassifier Validation Precision: 0.7874803797384721\n",
      "RandomForestClassifier Validation Recall: 0.7857769973661106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/06 20:25:52 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Training F1 Score: 0.731469561795964\n",
      "SVC Training Precision: 0.7544839245352881\n",
      "SVC Training Recall: 0.7431855500821019\n",
      "SVC Validation F1 Score: 0.7088681823804714\n",
      "SVC Validation Precision: 0.7339161906696655\n",
      "SVC Validation Recall: 0.7209455022980958\n",
      "Performing Grid Search for KNN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/05 17:48:23 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Training F1 Score: 0.86870304428356\n",
      "Naive Bayes Training Precision: 0.8734729655368948\n",
      "Naive Bayes Training Recall: 0.870272783632982\n",
      "Naive Bayes Validation F1 Score: 0.7782802540920541\n",
      "Naive Bayes Validation Precision: 0.7846659395802227\n",
      "Naive Bayes Validation Recall: 0.7822651448639157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/06 20:26:08 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Training F1 Score: 0.8247413837493035\n",
      "KNN Training Precision: 0.8305193403409592\n",
      "KNN Training Recall: 0.8273403595784253\n",
      "KNN Validation F1 Score: 0.7555838177878885\n",
      "KNN Validation Precision: 0.7620752382663547\n",
      "KNN Validation Recall: 0.7603160667251976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/06 20:26:16 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training F1 Score: 0.8436545450751911\n",
      "XGBoost Training Precision: 0.8572830449371619\n",
      "XGBoost Training Recall: 0.847334159950403\n",
      "XGBoost Validation F1 Score: 0.7707382424445831\n",
      "XGBoost Validation Precision: 0.7806826590989302\n",
      "XGBoost Validation Recall: 0.7761194029850746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/06 20:26:20 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Training F1 Score: 0.8593260438056409\n",
      "Logistic Regression Training Precision: 0.8679312620431813\n",
      "Logistic Regression Training Recall: 0.8617482951022939\n",
      "Logistic Regression Validation F1 Score: 0.777894968203914\n",
      "Logistic Regression Validation Precision: 0.7914551062193333\n",
      "Logistic Regression Validation Recall: 0.7840210711150132\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    train_and_evaluate(model,  X_train_vect, y_train, X_val_vect, y_val, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Voting & Stacking Classifiers with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VotingClassifier with the best models\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    # ('rf', models['RandomForestClassifier']),\n",
    "    # ('svc', models['SVC']),\n",
    "    ('nb', models['Naive Bayes']),\n",
    "    # ('knn', models['KNN']),\n",
    "    ('xgb', models['XGBoost']),\n",
    "    ('lr',  models['Logistic Regression']),\n",
    "], voting='hard')\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators=[\n",
    "    # ('rf', models['RandomForestClassifier']),\n",
    "    # ('svc', models['SVC']),\n",
    "    ('nb', models['Naive Bayes']),\n",
    "    # ('knn', models['KNN']),\n",
    "    ('xgb', models['XGBoost']),\n",
    "        ('lr',  models['Logistic Regression']),\n",
    "\n",
    "], final_estimator=LogisticRegression(),\n",
    "    cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cceef64eaf4e729c2cec6e9363e814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble_VotingClassifier Training F1 Score: 0.863603770780156\n",
      "Ensemble_VotingClassifier Training Precision: 0.8722241400949332\n",
      "Ensemble_VotingClassifier Training Recall: 0.8659330440173589\n",
      "Ensemble_VotingClassifier Validation F1 Score: 0.7912193359751131\n",
      "Ensemble_VotingClassifier Validation Precision: 0.8028585655908783\n",
      "Ensemble_VotingClassifier Validation Recall: 0.7963125548726954\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_ensemble(model, X_train, y_train, X_val, y_val, model_name):\n",
    "    with mlflow.start_run(run_name=model_name, experiment_id=experiment_id) as run:\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        # Calculate metrics for training set\n",
    "        train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "        train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "        train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "        # Calculate metrics for validation set\n",
    "        val_f1 = f1_score(y_val, y_val_pred, average='weighted')\n",
    "        val_precision = precision_score(y_val, y_val_pred, average='weighted')\n",
    "        val_recall = recall_score(y_val, y_val_pred, average='weighted')\n",
    "\n",
    "        # Log parameters and metrics\n",
    "        mlflow.log_param(\"ensemble_method\", \"VotingClassifier\")\n",
    "        mlflow.log_metric(\"train_f1_score\", train_f1)\n",
    "        mlflow.log_metric(\"train_precision\", train_precision)\n",
    "        mlflow.log_metric(\"train_recall\", train_recall)\n",
    "        mlflow.log_metric(\"val_f1_score\", val_f1)\n",
    "        mlflow.log_metric(\"val_precision\", val_precision)\n",
    "        mlflow.log_metric(\"val_recall\", val_recall)\n",
    "\n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, model_name, input_example=X_train[:30])\n",
    "\n",
    "        # Print metrics\n",
    "        print(f'{model_name} Training F1 Score: {train_f1}')\n",
    "        print(f'{model_name} Training Precision: {train_precision}')\n",
    "        print(f'{model_name} Training Recall: {train_recall}')\n",
    "        print(f'{model_name} Validation F1 Score: {val_f1}')\n",
    "        print(f'{model_name} Validation Precision: {val_precision}')\n",
    "        print(f'{model_name} Validation Recall: {val_recall}')\n",
    "\n",
    "# Train and evaluate the ensemble model\n",
    "train_and_evaluate_ensemble(voting_clf, X_train_vect, y_train, X_val_vect, y_val, \"Ensemble_VotingClassifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43a6598e72c4dc0a11eae30d8b24f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble_StackingClassifier Training F1 Score: 0.8749792125648127\n",
      "Ensemble_StackingClassifier Training Precision: 0.8790034884796407\n",
      "Ensemble_StackingClassifier Training Recall: 0.8763174209547427\n",
      "Ensemble_StackingClassifier Validation F1 Score: 0.7945039994239871\n",
      "Ensemble_StackingClassifier Validation Precision: 0.7983152842613692\n",
      "Ensemble_StackingClassifier Validation Recall: 0.797190517998244\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_ensemble(stacking_clf, X_train_vect, y_train, X_val_vect, y_val, \"Ensemble_StackingClassifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking UI: NgrokTunnel: \"https://5c31-41-82-155-235.ngrok-free.app\" -> \"http://localhost:5000\"\n"
     ]
    }
   ],
   "source": [
    "# Terminate open tunnels if they exist\n",
    "ngrok.kill()\n",
    "NGROK_AUTH_TOKEN = \"2iXzpfikPynAXlcC1qn3NDhkhMS_7BbPuGQ5Sc8R7aohgotz6\"\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "public_url = ngrok.connect(5000)\n",
    "print(\"MLflow Tracking UI:\", public_url)\n",
    "\n",
    "# Transition models to production\n",
    "client = MlflowClient()\n",
    "for model_name in models.keys():\n",
    "    try:\n",
    "        model_versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "        if model_versions:\n",
    "            # Get the latest model version\n",
    "            latest_version = model_versions[-1]\n",
    "            client.transition_model_version_stage(\n",
    "                name=model_name,\n",
    "                version=latest_version.version,\n",
    "                stage=\"production\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Error transitioning model {model_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"3\"></a> \n",
    "#### 4. Pipeline [‚èÆÔ∏è](#4)[üëÜüèΩ](#0)[‚è≠Ô∏è](#6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m idf_pip\u001b[38;5;241m=\u001b[39m\u001b[43mPipeline\u001b[49m(\n\u001b[0;32m      2\u001b[0m                 [\n\u001b[0;32m      3\u001b[0m                     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf_idf\u001b[39m\u001b[38;5;124m'\u001b[39m,TfidfVectorizer(ngram_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))),\n\u001b[0;32m      4\u001b[0m                     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m,LogisticRegression(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.8\u001b[39m,solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m'\u001b[39m,max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m))\n\u001b[0;32m      5\u001b[0m                 ]\n\u001b[0;32m      6\u001b[0m                 )\n\u001b[0;32m      7\u001b[0m idf_pip\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "idf_pip=Pipeline(\n",
    "                [\n",
    "                    ('tf_idf',TfidfVectorizer(ngram_range=(1,1))),\n",
    "                    ('model',LogisticRegression(C=.8,solver='sag',max_iter=1000))\n",
    "                ]\n",
    "                )\n",
    "idf_pip.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> \n",
    "#### Conclusion [‚èÆÔ∏è](#4)[üëÜüèΩ](#0)[‚è≠Ô∏è](#6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"6\"></a> \n",
    "#### <i>References</i> [‚èÆÔ∏è](#5)[üëÜüèΩ](#0)[‚è≠Ô∏è](#7)\n",
    "Here is some text with a reference to the [Python documentation](https://docs.python.org/).\n",
    "\n",
    "...\n",
    "\n",
    "Here are some references for more information on the libraries used:\n",
    "\n",
    "- [Pandas documentation](https://pandas.pydata.org/docs/)\n",
    "- [NumPy documentation](https://numpy.org/doc/stable/)\n",
    "- [Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html)\n",
    "\n",
    "üçÄ Auteurs\n",
    "- üßëüèæ‚Äçüíª Kikia DIA\n",
    "- üßëüèæ‚Äçüíª Mouhamadou Naby DIA\n",
    "- üßëüèæ‚Äçüíª Ndeye Awa SALANE\n",
    "\n",
    "üçÄ Affiliations\n",
    "- üéì Ecole Polytechnique de THIES\n",
    "\n",
    "üçÄ D√©partement \n",
    "- üíª G√©nie Informatique et T√©l√©communications\n",
    "\n",
    "üçÄ Niveau\n",
    "- üìö DIC3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
