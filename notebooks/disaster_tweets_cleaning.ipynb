{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h5 style=\"text-align: center; color: #BD6C49;\"> <i> Ecole Polytechnique de Thi√®s <br>  D√©partement G√©nie Informatique et T√©l√©communication </i> </h5>\n",
    "<h3 style=\"text-align: center; color: orange\"> Disaster Tweets Detection ü•á Exploratory Data Analysis </h3>\n",
    "<h5 style=\"text-align: center; color: green\"> By Kikia DIA ü§ùüèæ Mouhamadou Naby DIA ü§ùüèæ Ndeye Awa SALANE </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"0\"></a> <br>\n",
    "### Overview\n",
    "#### [Introduction](#1)\n",
    "1. [Exercice 1 La biblioth√®que PIL](#2)\n",
    "1. [Exercice 2 Numpy, MatplotLib](#3)\n",
    "1. [Exercice 3 ScikitLearn](#4)\n",
    "1. [Exercice 4 Scipy](#8)\n",
    "#### [Conclusion](#5)\n",
    "* <i>[References](#6)</i>\n",
    "* <i>[Authors](#7)</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> \n",
    "#### Introduction [‚èÆÔ∏è]()[üëÜüèΩ](#0)[‚è≠Ô∏è](#2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex;\">\n",
    "     <div style=\"flex: 1;\">\n",
    "         <img src=\"https://storage.googleapis.com/kaggle-media/competitions/tweet_screenshot.png\" alt=\"Descriptive Image\" style=\"height:90%;\">\n",
    "     </div>\n",
    "     <div style=\"flex: 4; padding-top: 10px;\">\n",
    "         <p>\n",
    "             ‚ôªÔ∏è Twitter est devenu un important canal de communication en cas d‚Äôurgence.\n",
    "             <br><br>\n",
    "             ‚ôªÔ∏è L‚Äôomnipr√©sence des smartphones permet aux gens d‚Äôannoncer une urgence qu‚Äôils observent en temps r√©el. Pour cette raison, de plus en plus d‚Äôorganismes s‚Äôint√©ressent √† la surveillance programmatique de Twitter (c.-√†-d. les organisations de secours aux sinistr√©s et les agences de presse).\n",
    "             <br><br>\n",
    "             ‚ôªÔ∏è Mais on ne sait pas toujours si les paroles d‚Äôune personne annoncent r√©ellement un d√©sastre (comme en t√©moigne l'image ci-contre).\n",
    "             <br><br>\n",
    "             ‚ôªÔ∏è L‚Äôauteur utilise explicitement le mot ¬´¬†ABLAZE¬†¬ª (qui veut dire \"En Feu\") mais le dit m√©taphoriquement, ce qui est clair pour un homme d√®s le d√©part, surtout avec l‚Äôaide visuelle. Mais c‚Äôest moins clair pour une machine.\n",
    "             <br><br>\n",
    "             ‚ôªÔ∏è C‚Äôest pourquoi nous avons choisis d‚Äôutiliser un mod√®le de langage qui pr√©dit quels Tweets sont sur des catastrophes r√©elles et lesquels ne le sont pas. Nous allons utiliser √† un ensemble de donn√©es de 10000 tweets qui ont √©t√© classifi√©s. \n",
    "         </p>\n",
    "     </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter le r√©pertoire parent pour les imports de module\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les logs\n",
    "from src.logging.main import LoggerManager\n",
    "\n",
    "log = LoggerManager('disaster_tweets_logging.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "from collections import  Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/raw/train.csv')\n",
    "test = pd.read_csv('../data/raw/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ôªÔ∏è Removing URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example=\"New competition launched: https://www.kaggle.com/c/nlp-getting-started\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New competition launched: '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "remove_URL(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']= train['text'].apply(lambda x : remove_URL(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ôªÔ∏è Removing HTML tags¬∂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\"<div>\n",
    "<h1>Real or Fake</h1>\n",
    "<p>Kaggle </p>\n",
    "<a href=\"https://www.kaggle.com/c/nlp-getting-started\">getting started</a>\n",
    "</div>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Real or Fake\n",
      "Kaggle \n",
      "getting started\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "print(remove_html(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']= train['text'].apply(lambda x : remove_html(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ôªÔ∏è Removing Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Omg another Earthquake '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "remove_emoji(\"Omg another Earthquake üòîüòî\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']= train['text'].apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ôªÔ∏è Removing punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a king\n"
     ]
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "example=\"I am a #king\"\n",
    "print(remove_punct(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text']= train['text'].apply(lambda x : remove_punct(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ôªÔ∏è Spelling Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'correct me please'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell = SpellChecker()\n",
    "def correct_spellings(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        corrected_word = spell.correction(word) if word in misspelled_words else word\n",
    "        corrected_text.append(corrected_word if corrected_word is not None else \"\")\n",
    "    return \" \".join(corrected_text)\n",
    "        \n",
    "text = \"corect me plese\"\n",
    "correct_spellings(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "def correct_spellings(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        corrected_word = spell.correction(word) if word in misspelled_words else word\n",
    "        corrected_text.append(corrected_word if corrected_word is not None else \"\")\n",
    "    return \" \".join(corrected_text)\n",
    "\n",
    "# Apply the function to the 'text' column\n",
    "train['text'] = train['text'].apply(lambda x: correct_spellings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'keyword' column\n",
    "train['keyword'] = train['keyword'].apply(lambda x: correct_spellings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the 'keyword' column\n",
    "train['location'] = train['location'].apply(lambda x: correct_spellings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../data/processed/train.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 42s, sys: 565 ms, total: 16min 42s\n",
      "Wall time: 16min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test['text']= test['text'].apply(lambda x : remove_URL(x))\n",
    "test['text']= test['text'].apply(lambda x : remove_html(x))\n",
    "test['text']= test['text'].apply(lambda x: remove_emoji(x))\n",
    "test['text']= test['text'].apply(lambda x : remove_punct(x))\n",
    "test['text'] = test['text'].apply(lambda x: correct_spellings(x))\n",
    "test['keyword'] = test['keyword'].apply(lambda x: correct_spellings(x))\n",
    "test['location'] = test['location'].apply(lambda x: correct_spellings(x))\n",
    "test.to_csv('../data/processed/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Our Deeds are the Reason of this earthquake Ma...\n",
       "1                 Forest fire near La Ronge Sask Canada\n",
       "2     All residents asked to shelter in place are be...\n",
       "3     13000 people receive wildfires evacuation orde...\n",
       "4     Just got sent this photo from Ruby Alaska as s...\n",
       "5     RockyFire Update  California Hwy 20 closed in ...\n",
       "6     flood disaster Heavy rain causes flash floodin...\n",
       "7     Im on top of the hill and I can see a fire in ...\n",
       "8     Theres an emergency evacuation happening now i...\n",
       "9      Im afraid that the tornado is coming to our area\n",
       "10          Three people died from the heat wave so far\n",
       "11    Haha South Tampa is getting flooded hah WAIT A...\n",
       "12    raining flooding Florida TampaBay Tampa 18 or ...\n",
       "13                Flood in Bago Myanmar We arrived Bago\n",
       "14    Damage to school bus on 80 in multi car crash ...\n",
       "15                                         Whats up man\n",
       "16                                        I love fruits\n",
       "17                                     Summer is lovely\n",
       "18                                    My car is so fast\n",
       "19                               What a goooooooaaaaaal\n",
       "20                                   this is ridiculous\n",
       "21                                      London is cool \n",
       "22                                          Love skiing\n",
       "23                                 What a wonderful day\n",
       "24                                             LOOOOOOL\n",
       "25                           No wayI cant eat that shit\n",
       "26                                 Was in NYC last week\n",
       "27                                   Love my girlfriend\n",
       "28                                              Cooool \n",
       "29                                    Do you like pasta\n",
       "30                                              The end\n",
       "31                     bbcmtd Wholesale Markets ablaze \n",
       "32           We always try to bring the heavy metal RT \n",
       "33    AFRICANBAZE Breaking newsNigeria flag set abla...\n",
       "34                    Crying out for more Set me ablaze\n",
       "35    On plus side LOOK AT THE SKY LAST NIGHT IT WAS...\n",
       "36    PhDSquares mufc theyve built so much hype arou...\n",
       "37                     INEC Office in Abia Set Ablaze  \n",
       "38    Barbados Bridgetown JAMAICA ¬â√õ√í Two cars set a...\n",
       "39                                Ablaze for you Lord D\n",
       "40                             Check these out     nsfw\n",
       "41    on the outside youre ablaze and alive\\nbut you...\n",
       "42    Had an awesome time visiting the CFC head offi...\n",
       "43              SOOOO PUMPED FOR ABLAZE  southridgelife\n",
       "44    I wanted to set Chicago ablaze with my preachi...\n",
       "45    I gained 3 followers in the last week You Know...\n",
       "46    How the West was burned Thousands of wildfires...\n",
       "47    Building the perfect tracklist to life leave t...\n",
       "48                             Check these out     nsfw\n",
       "49    First night with retainers in Its quite weird ...\n",
       "50    Deputies Man shot before Brighton home set abl...\n",
       "51    Man wife get six years jail for setting ablaze...\n",
       "52    SANTA CRUZ ¬â√õ√ì Head of the St Elizabeth Police...\n",
       "53    Police Arsonist Deliberately Set Black Church ...\n",
       "54    Noches ElBestia AlexisSanchez happy to see my ...\n",
       "55    Kurds trampling on Turkmen flag later set it a...\n",
       "56    TRUCK ABLAZE  R21 VOORTREKKER AVE OUTSIDE OR T...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'].head(57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a> \n",
    "#### 1. Exercice 1 La biblioth√®que PIL [‚èÆÔ∏è](#1)[üëÜüèΩ](#0)[‚è≠Ô∏è](#3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> \n",
    "#### 2. Exercice 2 Numpy, MatplotLib [‚èÆÔ∏è](#2)[üëÜüèΩ](#0)[‚è≠Ô∏è](#4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a> \n",
    "#### 3. Exercice 3 ScikitLearn [‚èÆÔ∏è](#3)[üëÜüèΩ](#0)[‚è≠Ô∏è](#5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a> \n",
    "#### 4. Exercice 4 Scipy [‚èÆÔ∏è](#3)[üëÜüèΩ](#0)[‚è≠Ô∏è](#5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> \n",
    "#### Conclusion [‚èÆÔ∏è](#4)[üëÜüèΩ](#0)[‚è≠Ô∏è](#6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> \n",
    "#### <i>References</i> [‚èÆÔ∏è](#5)[üëÜüèΩ](#0)[‚è≠Ô∏è](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some text with a reference to the [Python documentation](https://docs.python.org/).\n",
    "\n",
    "...\n",
    "\n",
    "Here are some references for more information on the libraries used:\n",
    "\n",
    "- [Pandas documentation](https://pandas.pydata.org/docs/)\n",
    "- [NumPy documentation](https://numpy.org/doc/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a> \n",
    "#### <i>Authors</i> [‚èÆÔ∏è](#6)[üëÜüèΩ](#0)[‚è≠Ô∏è]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üçÄ Auteurs\n",
    "- üßëüèæ‚Äçüíª Kikia DIA\n",
    "- üßëüèæ‚Äçüíª Mouhamadou Naby DIA\n",
    "- üßëüèæ‚Äçüíª Ndeye Awa SALANE\n",
    "\n",
    "üçÄ Affiliations\n",
    "- üéì Ecole Polytechnique de THIES\n",
    "\n",
    "üçÄ D√©partement \n",
    "- üíª Genie Informatique et Telecoms\n",
    "\n",
    "üçÄ Niveau\n",
    "- üìö DIC2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
